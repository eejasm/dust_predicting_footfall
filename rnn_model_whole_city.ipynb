{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d6ab199-b664-422f-b148-8fd3b821a929",
   "metadata": {},
   "source": [
    "# Applying prediction model to data accumulated over the whole city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a038e97-94f8-4937-89b1-0730f9650e00",
   "metadata": {},
   "source": [
    "This notebook runs the same architecture as sensor_rnn_model and sensor_rnn_sliding_window except applied to a different dataset. In thes dataset used here, all the footfalls are accumulated at each timestep. This is in order to try and predict the footfall for the entire city at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cbe6a2-1366-47c2-8726-9eaae4bf33c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import sklearn\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Dropout, Embedding, Masking, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#!pip install seaborn\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e8dce-b37b-4981-9a67-2f2f1df89c5c",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141dd8c8-f3af-4eef-b19b-7f85fe89da72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_x_y_data(input_csv):\n",
    "    # Read in formatted data\n",
    "    data = pd.read_csv(input_csv, index_col = False)\n",
    "    data = data.fillna(0)\n",
    "    \n",
    "    ### Delete unneeded columns - we currently include data from all sensors (even incomplete ones)\n",
    "    sensor_ids = data['sensor_id']\n",
    "    #data = data.drop(['sensor_id'],axis=1) # don't want this included\n",
    "    # Get rid of columns in which none of the sensors have a value\n",
    "    for column in data.columns:\n",
    "        if np.nanmax(data[column]) ==0:\n",
    "            del data[column]\n",
    "            \n",
    "    # Filter columns using the regex pattern in function input\n",
    "    regex_pattern = 'buildings$|street_inf$|landmarks$'\n",
    "    data = data[data.columns.drop(list(data.filter(regex=regex_pattern)))].copy()\n",
    "    \n",
    "    ### Add a random variable (to compare performance of other variables against)\n",
    "    rng = np.random.RandomState(seed=42)\n",
    "    data['random'] = np.random.random(size=len(data))\n",
    "    data[\"random_cat\"] = rng.randint(3, size=data.shape[0])\n",
    "    \n",
    "    ## Prepare data for modelling \n",
    "    ### Split into predictor/predictand variables\n",
    "    Xfull = data.drop(['hourly_counts'], axis =1)\n",
    "    Yfull = data['hourly_counts'].values\n",
    "       \n",
    "    ### Store the (non Sin/Cos) time columns and then remove them (Need them later to segment the results by hour of the day)\n",
    "    data_time_columns = Xfull[['day_of_month_num', 'time', 'weekday_num', 'time_of_day', 'datetime']]\n",
    "    #Xfull = Xfull.drop(['day_of_month_num', 'time', 'weekday_num', 'time_of_day','datetime', 'month_num'],axis=1)\n",
    "    Xfull = Xfull.drop(['day_of_month_num', 'time', 'weekday_num', 'time_of_day', 'month_num'],axis=1)\n",
    "    return Xfull, Yfull, data_time_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19141b78-80e0-4213-b157-1ec80e5a91b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data normalizing function\n",
    "def normalize(df, target_column):\n",
    "    \n",
    "    result = df.copy()\n",
    "    \n",
    "    for feature_name in df.columns:\n",
    "        \n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        \n",
    "        if feature_name == 'footfall':\n",
    "            result['footfall_norm'] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "            \n",
    "        else:\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    \n",
    "    cols = list(result.columns)\n",
    "    column_list = cols[:-2] + cols[-1:] + cols[-2:-1]\n",
    "    result = result[column_list]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78429c73-fbb4-4295-8b82-76fbf8285283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in the raw data - see .README file for info on the raw data\n",
    "buffer_size_m = 400\n",
    "input_csv =\"/lustre_scratch/eejasm/DUST/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m)\n",
    "\n",
    "X_data, Y_data, data_time_columns = prepare_x_y_data(input_csv)\n",
    "\n",
    "X_data = X_data.iloc[:2198889]\n",
    "Y_data = Y_data[:2198889]\n",
    "data_time_columns = data_time_columns.iloc[:2198889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54460955-a59e-4f0c-960f-02058619fb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create df to combine the x and y data\n",
    "df = X_data.copy()\n",
    "\n",
    "df = df.loc[:,['datetime', 'Temp', 'Humidity' ,'Pressure', 'Rain', 'WindSpeed', 'Rainfall amount (millimetres)',\n",
    "               'Sin_time','Cos_time','Sin_month_num','Cos_month_num','Sin_weekday_num','Cos_weekday_num']] \n",
    "\n",
    "df['footfall'] = Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5077726a-eaac-423b-b96e-e276dce060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to accumulate the footfall number at each sensor for each timestep\n",
    "# first find all the unique timesteps\n",
    "city_df = df.iloc[:,:-1].drop_duplicates(keep='first').reset_index(drop=True)\n",
    "# then  group the timesteps and accumulate the footfall\n",
    "footfall = list(df.loc[:, ['datetime', 'footfall']].groupby(['datetime']).sum()['footfall'])\n",
    "city_df['footfall'] = footfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a6f46f-7393-4a66-b5e6-acc379ce863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find min and max values from the dataset\n",
    "footfall_max = city_df['footfall'].max()\n",
    "footfall_min = city_df['footfall'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f03eb684-80b3-4ff0-bb53-0074ebae319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any unwanted features\n",
    "city_df = city_df.drop(columns = ['datetime', 'Temp', 'Humidity' ,'Pressure', 'Rain', 'WindSpeed', 'Rainfall amount (millimetres)',\n",
    "                                   'Sin_time','Cos_time','Sin_month_num','Cos_month_num','Sin_weekday_num','Cos_weekday_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34492e63-4ec0-41d7-89a7-96dcf261795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test, val and train sets\n",
    "n=len(city_df)\n",
    "\n",
    "train_df = city_df[0:int(n*0.7)]\n",
    "val_df = city_df[int(n*0.7):int(n*0.9)]\n",
    "test_df = city_df[int(n*0.9):]\n",
    "\n",
    "train_df = train_df.dropna(axis='columns')\n",
    "val_df = val_df.dropna(axis='columns')\n",
    "test_df = test_df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0baee2bb-5a1e-4e04-8a0f-e436fd8faa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>footfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50324</th>\n",
       "      <td>7302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50325</th>\n",
       "      <td>3110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50326</th>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50327</th>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50328</th>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50329 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       footfall\n",
       "0          5880\n",
       "1          8111\n",
       "2         10310\n",
       "3          8079\n",
       "4          3774\n",
       "...         ...\n",
       "50324      7302\n",
       "50325      3110\n",
       "50326      1490\n",
       "50327       920\n",
       "50328       731\n",
       "\n",
       "[50329 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590b640-e695-4fda-88ff-183131e1fba3",
   "metadata": {},
   "source": [
    "## Time series forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f25898-97bf-4a72-aa6c-9ff85be8f51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a window generator that generates windows of data for input into model training\n",
    "# also has a plotting routine to check the results\n",
    "\n",
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=None):\n",
    "        \n",
    "        # Store the raw data.\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "    \n",
    "        # Work out the label column indices.\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in\n",
    "                                        enumerate(label_columns)}\n",
    "        \n",
    "        self.column_indices = {name: i for i, name in\n",
    "                            enumerate(train_df.columns)}\n",
    "    \n",
    "        # Work out the window parameters.\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "    \n",
    "        self.total_window_size = input_width + shift\n",
    "    \n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "    \n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    \n",
    "    def split_window(self, features):\n",
    "        \n",
    "        inputs = features[:, self.input_slice, -1:]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        #print(inputs.shape)\n",
    "        #inputs[:,:,-1] = (inputs[:,:,-1] - footfall_min) / (footfall_max - footfall_min)\n",
    "\n",
    "        \n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns],axis=-1)\n",
    "    \n",
    "        # Slicing doesn't preserve static shape information, so set the shapes\n",
    "        # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "    \n",
    "        return inputs, labels\n",
    "    \n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32,)\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "    \n",
    "    # a plot function to view a few examples of how the footfall prediction compares to the observed value\n",
    "    def plot(self, model=None, plot_col='footfall', max_subplots=10):\n",
    "    \n",
    "        inputs, labels = self.example\n",
    "        plt.figure(figsize=(12, 18))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "        print(max_n)\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(max_n, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [normed]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index-1],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "        \n",
    "            if self.label_columns:\n",
    "                label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "                label_col_index = plot_col_index\n",
    "        \n",
    "            if label_col_index is None:\n",
    "                continue\n",
    "        \n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "            if model is not None:\n",
    "                predictions = model(inputs)\n",
    "                plt.scatter(self.label_indices, predictions[n,label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='#ff7f0e', s=64)\n",
    "        \n",
    "            if n == 0:\n",
    "                plt.legend()\n",
    "        \n",
    "        plt.xlabel('Time [h]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77560eb1-aba1-4526-8bb8-13f15ca3f58a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set epochs and function for compile/training the model\n",
    "MAX_EPOCHS = 200\n",
    "\n",
    "def compile_and_fit(model, window, patience=3):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                      patience=patience,\n",
    "                                                      mode='min')\n",
    "\n",
    "    model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                        validation_data=window.val,\n",
    "                        callbacks=[early_stopping],\n",
    "                       verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e3d8a9a-3e41-4274-9c86-9f5700102dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup window with required parameters\n",
    "w2 = WindowGenerator(input_width=6, label_width=1, shift=1, label_columns=['footfall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da1560d0-bcf2-4c54-af57-9343d21b7818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 13:20:33.046412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-26 13:20:34.496740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30927 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2024-01-26 13:20:34.524147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30927 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:0b:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "908776cd-0208-44b4-b268-7350d6ba36cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (batch, time, features)\n",
      "Window shape: (3, 7, 1)\n",
      "Inputs shape: (3, 6, 1)\n",
      "Labels shape: (3, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# set to check output looks correct\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da2c7447-6e3c-4910-b611-6c3ca55f67fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the WindowGenerator object holds training, validation, and test data. \n",
    "# Here add properties for accessing them as tf.data.Datasets using the make_dataset method you defined earlier\n",
    "\n",
    "@property\n",
    "def train(self):\n",
    "    return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "    return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "    return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "    \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "    result = getattr(self, '_example', None)\n",
    "    if result is None:\n",
    "      # No example batch was found, so get one from the `.train` dataset\n",
    "      result = next(iter(self.train))\n",
    "      # And cache it for next time\n",
    "      self._example = result\n",
    "    return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4df2a61e-007f-4574-9473-a4ec0abd5ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 6, 1)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# check each batch before going into training\n",
    "for example_inputs, example_labels in w2.train.take(1):\n",
    "    print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "    print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cb3c65f-c7cf-4fd4-b419-f59642694fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup the LSTM model\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5694da6c-bd89-4c55-9abe-cc8b8984bb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 13:20:38.556844: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1573/1573 [==============================] - 10s 4ms/step - loss: 220090256.0000 - mean_absolute_error: 11783.9004 - val_loss: 431458688.0000 - val_mean_absolute_error: 17614.8418\n",
      "Epoch 2/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 219389696.0000 - mean_absolute_error: 11754.1465 - val_loss: 430379744.0000 - val_mean_absolute_error: 17584.2031\n",
      "Epoch 3/200\n",
      "1573/1573 [==============================] - 7s 5ms/step - loss: 218684976.0000 - mean_absolute_error: 11724.1230 - val_loss: 429302048.0000 - val_mean_absolute_error: 17553.5234\n",
      "Epoch 4/200\n",
      "1573/1573 [==============================] - 8s 5ms/step - loss: 217971072.0000 - mean_absolute_error: 11693.6572 - val_loss: 428255648.0000 - val_mean_absolute_error: 17523.6895\n",
      "Epoch 5/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 217278096.0000 - mean_absolute_error: 11663.9912 - val_loss: 427219104.0000 - val_mean_absolute_error: 17494.0957\n",
      "Epoch 6/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 216588816.0000 - mean_absolute_error: 11634.5498 - val_loss: 426185728.0000 - val_mean_absolute_error: 17464.5293\n",
      "Epoch 7/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 215902512.0000 - mean_absolute_error: 11605.3682 - val_loss: 425154528.0000 - val_mean_absolute_error: 17435.0078\n",
      "Epoch 8/200\n",
      "1573/1573 [==============================] - 7s 5ms/step - loss: 215217232.0000 - mean_absolute_error: 11576.5029 - val_loss: 424125088.0000 - val_mean_absolute_error: 17405.4238\n",
      "Epoch 9/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 214533632.0000 - mean_absolute_error: 11548.0596 - val_loss: 423097184.0000 - val_mean_absolute_error: 17375.8691\n",
      "Epoch 10/200\n",
      "1573/1573 [==============================] - 7s 4ms/step - loss: 213852096.0000 - mean_absolute_error: 11519.9443 - val_loss: 422070688.0000 - val_mean_absolute_error: 17346.3086\n",
      "Epoch 11/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 213167056.0000 - mean_absolute_error: 11491.9023 - val_loss: 421009568.0000 - val_mean_absolute_error: 17315.7129\n",
      "Epoch 12/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 212424608.0000 - mean_absolute_error: 11461.5830 - val_loss: 419854976.0000 - val_mean_absolute_error: 17282.3359\n",
      "Epoch 13/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 211628752.0000 - mean_absolute_error: 11429.0703 - val_loss: 418580768.0000 - val_mean_absolute_error: 17245.4395\n",
      "Epoch 14/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 210754928.0000 - mean_absolute_error: 11393.4668 - val_loss: 417144512.0000 - val_mean_absolute_error: 17203.7734\n",
      "Epoch 15/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 209777776.0000 - mean_absolute_error: 11353.6084 - val_loss: 415718848.0000 - val_mean_absolute_error: 17162.4590\n",
      "Epoch 16/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 208850400.0000 - mean_absolute_error: 11315.7832 - val_loss: 414325056.0000 - val_mean_absolute_error: 17122.0254\n",
      "Epoch 17/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 207935040.0000 - mean_absolute_error: 11278.9209 - val_loss: 412940000.0000 - val_mean_absolute_error: 17082.4863\n",
      "Epoch 18/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 207004112.0000 - mean_absolute_error: 11241.4922 - val_loss: 411486112.0000 - val_mean_absolute_error: 17040.4922\n",
      "Epoch 19/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 206064448.0000 - mean_absolute_error: 11204.1943 - val_loss: 410092928.0000 - val_mean_absolute_error: 17000.5371\n",
      "Epoch 20/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 205151248.0000 - mean_absolute_error: 11168.4443 - val_loss: 408706400.0000 - val_mean_absolute_error: 16961.6621\n",
      "Epoch 21/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 204242320.0000 - mean_absolute_error: 11133.1133 - val_loss: 407322720.0000 - val_mean_absolute_error: 16922.4746\n",
      "Epoch 22/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 203336400.0000 - mean_absolute_error: 11098.0020 - val_loss: 405942880.0000 - val_mean_absolute_error: 16883.6094\n",
      "Epoch 23/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 202433808.0000 - mean_absolute_error: 11063.4883 - val_loss: 404566528.0000 - val_mean_absolute_error: 16845.1074\n",
      "Epoch 24/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 201534112.0000 - mean_absolute_error: 11028.6641 - val_loss: 403195104.0000 - val_mean_absolute_error: 16807.4219\n",
      "Epoch 25/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 200638080.0000 - mean_absolute_error: 10993.7988 - val_loss: 401824704.0000 - val_mean_absolute_error: 16768.5938\n",
      "Epoch 26/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 199744320.0000 - mean_absolute_error: 10959.5820 - val_loss: 400457344.0000 - val_mean_absolute_error: 16730.6699\n",
      "Epoch 27/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 198853120.0000 - mean_absolute_error: 10924.9688 - val_loss: 399093824.0000 - val_mean_absolute_error: 16692.8262\n",
      "Epoch 28/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 197965312.0000 - mean_absolute_error: 10890.4580 - val_loss: 397734176.0000 - val_mean_absolute_error: 16655.3066\n",
      "Epoch 29/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 197080736.0000 - mean_absolute_error: 10856.4443 - val_loss: 396377920.0000 - val_mean_absolute_error: 16618.0762\n",
      "Epoch 30/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 196199344.0000 - mean_absolute_error: 10822.7480 - val_loss: 395026528.0000 - val_mean_absolute_error: 16581.6250\n",
      "Epoch 31/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 195321264.0000 - mean_absolute_error: 10789.2021 - val_loss: 393675264.0000 - val_mean_absolute_error: 16544.1953\n",
      "Epoch 32/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 194445408.0000 - mean_absolute_error: 10755.5996 - val_loss: 392329152.0000 - val_mean_absolute_error: 16507.0625\n",
      "Epoch 33/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 193572496.0000 - mean_absolute_error: 10722.5166 - val_loss: 390984576.0000 - val_mean_absolute_error: 16470.7871\n",
      "Epoch 34/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 192703840.0000 - mean_absolute_error: 10691.0342 - val_loss: 389643712.0000 - val_mean_absolute_error: 16434.7285\n",
      "Epoch 35/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 191836256.0000 - mean_absolute_error: 10656.8750 - val_loss: 388309696.0000 - val_mean_absolute_error: 16400.6016\n",
      "Epoch 36/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 190972688.0000 - mean_absolute_error: 10623.6846 - val_loss: 386975776.0000 - val_mean_absolute_error: 16364.5566\n",
      "Epoch 37/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 190112064.0000 - mean_absolute_error: 10591.0635 - val_loss: 385643520.0000 - val_mean_absolute_error: 16324.8779\n",
      "Epoch 38/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 189215152.0000 - mean_absolute_error: 10556.7422 - val_loss: 384224928.0000 - val_mean_absolute_error: 16287.6631\n",
      "Epoch 39/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 188320016.0000 - mean_absolute_error: 10522.3076 - val_loss: 382845184.0000 - val_mean_absolute_error: 16249.8604\n",
      "Epoch 40/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 187434720.0000 - mean_absolute_error: 10488.7881 - val_loss: 381474080.0000 - val_mean_absolute_error: 16213.3311\n",
      "Epoch 41/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 186553056.0000 - mean_absolute_error: 10455.0850 - val_loss: 380108096.0000 - val_mean_absolute_error: 16177.9668\n",
      "Epoch 42/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 185674176.0000 - mean_absolute_error: 10421.7256 - val_loss: 378740928.0000 - val_mean_absolute_error: 16139.5830\n",
      "Epoch 43/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 184798768.0000 - mean_absolute_error: 10388.1836 - val_loss: 377382752.0000 - val_mean_absolute_error: 16105.6016\n",
      "Epoch 44/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 183925856.0000 - mean_absolute_error: 10355.0293 - val_loss: 376025440.0000 - val_mean_absolute_error: 16068.0186\n",
      "Epoch 45/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 183057248.0000 - mean_absolute_error: 10321.2764 - val_loss: 374672640.0000 - val_mean_absolute_error: 16032.0156\n",
      "Epoch 46/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 182190192.0000 - mean_absolute_error: 10288.5869 - val_loss: 373321440.0000 - val_mean_absolute_error: 15995.8232\n",
      "Epoch 47/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 181325680.0000 - mean_absolute_error: 10254.5361 - val_loss: 371975840.0000 - val_mean_absolute_error: 15963.3301\n",
      "Epoch 48/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 180464816.0000 - mean_absolute_error: 10221.9844 - val_loss: 370624864.0000 - val_mean_absolute_error: 15922.7461\n",
      "Epoch 49/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 179607792.0000 - mean_absolute_error: 10189.6416 - val_loss: 369285056.0000 - val_mean_absolute_error: 15886.7266\n",
      "Epoch 50/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 178752880.0000 - mean_absolute_error: 10156.6504 - val_loss: 367947392.0000 - val_mean_absolute_error: 15851.0771\n",
      "Epoch 51/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 177900448.0000 - mean_absolute_error: 10123.7148 - val_loss: 366620512.0000 - val_mean_absolute_error: 15818.2295\n",
      "Epoch 52/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 177051904.0000 - mean_absolute_error: 10091.3984 - val_loss: 365281344.0000 - val_mean_absolute_error: 15781.5166\n",
      "Epoch 53/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 176206352.0000 - mean_absolute_error: 10058.8701 - val_loss: 363955328.0000 - val_mean_absolute_error: 15747.5576\n",
      "Epoch 54/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 175363136.0000 - mean_absolute_error: 10025.5801 - val_loss: 362630080.0000 - val_mean_absolute_error: 15711.3359\n",
      "Epoch 55/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 174523488.0000 - mean_absolute_error: 9994.3564 - val_loss: 361303616.0000 - val_mean_absolute_error: 15673.7324\n",
      "Epoch 56/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 173684896.0000 - mean_absolute_error: 9961.1523 - val_loss: 359982688.0000 - val_mean_absolute_error: 15638.8926\n",
      "Epoch 57/200\n",
      "1573/1573 [==============================] - 6s 3ms/step - loss: 172852240.0000 - mean_absolute_error: 9929.9229 - val_loss: 358665152.0000 - val_mean_absolute_error: 15602.3438\n",
      "Epoch 58/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 172020848.0000 - mean_absolute_error: 9896.9824 - val_loss: 357355200.0000 - val_mean_absolute_error: 15570.5166\n",
      "Epoch 59/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 171192048.0000 - mean_absolute_error: 9865.5146 - val_loss: 356044992.0000 - val_mean_absolute_error: 15536.2061\n",
      "Epoch 60/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 170365296.0000 - mean_absolute_error: 9833.3281 - val_loss: 354739200.0000 - val_mean_absolute_error: 15502.0527\n",
      "Epoch 61/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 169540928.0000 - mean_absolute_error: 9800.2988 - val_loss: 353432768.0000 - val_mean_absolute_error: 15463.8711\n",
      "Epoch 62/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 168729136.0000 - mean_absolute_error: 9771.4355 - val_loss: 352143968.0000 - val_mean_absolute_error: 15436.8145\n",
      "Epoch 63/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 167812784.0000 - mean_absolute_error: 9737.5020 - val_loss: 350267392.0000 - val_mean_absolute_error: 15381.8418\n",
      "Epoch 64/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 166727664.0000 - mean_absolute_error: 9694.4902 - val_loss: 348958336.0000 - val_mean_absolute_error: 15347.7002\n",
      "Epoch 65/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 165911392.0000 - mean_absolute_error: 9664.1504 - val_loss: 347659232.0000 - val_mean_absolute_error: 15318.8662\n",
      "Epoch 66/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 165094880.0000 - mean_absolute_error: 9631.6143 - val_loss: 346359872.0000 - val_mean_absolute_error: 15280.2578\n",
      "Epoch 67/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 164283264.0000 - mean_absolute_error: 9601.2891 - val_loss: 345059264.0000 - val_mean_absolute_error: 15244.2529\n",
      "Epoch 68/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 163477728.0000 - mean_absolute_error: 9572.1270 - val_loss: 343790336.0000 - val_mean_absolute_error: 15216.4619\n",
      "Epoch 69/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 162669152.0000 - mean_absolute_error: 9537.8496 - val_loss: 342477952.0000 - val_mean_absolute_error: 15174.7959\n",
      "Epoch 70/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 161864608.0000 - mean_absolute_error: 9506.3848 - val_loss: 341196032.0000 - val_mean_absolute_error: 15141.1758\n",
      "Epoch 71/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 161066432.0000 - mean_absolute_error: 9477.0352 - val_loss: 339922976.0000 - val_mean_absolute_error: 15112.9658\n",
      "Epoch 72/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 160268208.0000 - mean_absolute_error: 9444.7793 - val_loss: 338637696.0000 - val_mean_absolute_error: 15078.0791\n",
      "Epoch 73/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 159474352.0000 - mean_absolute_error: 9413.6553 - val_loss: 337383008.0000 - val_mean_absolute_error: 15046.5430\n",
      "Epoch 74/200\n",
      "1573/1573 [==============================] - 6s 3ms/step - loss: 158683920.0000 - mean_absolute_error: 9384.1494 - val_loss: 336085728.0000 - val_mean_absolute_error: 15011.6982\n",
      "Epoch 75/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 157894592.0000 - mean_absolute_error: 9354.0391 - val_loss: 334841280.0000 - val_mean_absolute_error: 14983.6074\n",
      "Epoch 76/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 157103424.0000 - mean_absolute_error: 9318.6807 - val_loss: 333544800.0000 - val_mean_absolute_error: 14940.0068\n",
      "Epoch 77/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 156320560.0000 - mean_absolute_error: 9289.1504 - val_loss: 332283712.0000 - val_mean_absolute_error: 14908.5635\n",
      "Epoch 78/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 155545360.0000 - mean_absolute_error: 9262.0752 - val_loss: 331041120.0000 - val_mean_absolute_error: 14881.4072\n",
      "Epoch 79/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 154767728.0000 - mean_absolute_error: 9231.5166 - val_loss: 329787008.0000 - val_mean_absolute_error: 14852.6602\n",
      "Epoch 80/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 153993568.0000 - mean_absolute_error: 9201.5938 - val_loss: 328522272.0000 - val_mean_absolute_error: 14813.4922\n",
      "Epoch 81/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 153217216.0000 - mean_absolute_error: 9167.2178 - val_loss: 327256960.0000 - val_mean_absolute_error: 14777.9443\n",
      "Epoch 82/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 152446624.0000 - mean_absolute_error: 9137.4795 - val_loss: 326010112.0000 - val_mean_absolute_error: 14737.7041\n",
      "Epoch 83/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 151684816.0000 - mean_absolute_error: 9110.2158 - val_loss: 324775840.0000 - val_mean_absolute_error: 14718.1904\n",
      "Epoch 84/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 150918896.0000 - mean_absolute_error: 9078.3193 - val_loss: 323545696.0000 - val_mean_absolute_error: 14695.0156\n",
      "Epoch 85/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 150160944.0000 - mean_absolute_error: 9052.9512 - val_loss: 322295264.0000 - val_mean_absolute_error: 14651.7168\n",
      "Epoch 86/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 149402992.0000 - mean_absolute_error: 9024.2129 - val_loss: 321050816.0000 - val_mean_absolute_error: 14617.7334\n",
      "Epoch 87/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 148639552.0000 - mean_absolute_error: 8987.6865 - val_loss: 319835232.0000 - val_mean_absolute_error: 14590.2432\n",
      "Epoch 88/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 147890208.0000 - mean_absolute_error: 8957.4980 - val_loss: 318608064.0000 - val_mean_absolute_error: 14555.8760\n",
      "Epoch 89/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 146645472.0000 - mean_absolute_error: 8908.9795 - val_loss: 316561632.0000 - val_mean_absolute_error: 14501.0781\n",
      "Epoch 90/200\n",
      "1573/1573 [==============================] - 6s 4ms/step - loss: 147353840.0000 - mean_absolute_error: 8942.7090 - val_loss: 319326560.0000 - val_mean_absolute_error: 14568.6221\n",
      "Epoch 91/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 145450176.0000 - mean_absolute_error: 8866.5312 - val_loss: 314108160.0000 - val_mean_absolute_error: 14432.7910\n",
      "Epoch 92/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 144406944.0000 - mean_absolute_error: 8822.1094 - val_loss: 312857152.0000 - val_mean_absolute_error: 14389.2676\n",
      "Epoch 93/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 143667776.0000 - mean_absolute_error: 8794.8018 - val_loss: 311647776.0000 - val_mean_absolute_error: 14362.6172\n",
      "Epoch 94/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 142929056.0000 - mean_absolute_error: 8767.1328 - val_loss: 310422592.0000 - val_mean_absolute_error: 14327.9795\n",
      "Epoch 95/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 142181664.0000 - mean_absolute_error: 8731.8584 - val_loss: 309203168.0000 - val_mean_absolute_error: 14292.8076\n",
      "Epoch 96/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 141448320.0000 - mean_absolute_error: 8702.6689 - val_loss: 307979392.0000 - val_mean_absolute_error: 14256.0098\n",
      "Epoch 97/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 140717424.0000 - mean_absolute_error: 8676.5449 - val_loss: 306773280.0000 - val_mean_absolute_error: 14231.3633\n",
      "Epoch 98/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 139985328.0000 - mean_absolute_error: 8645.2871 - val_loss: 305597408.0000 - val_mean_absolute_error: 14203.2451\n",
      "Epoch 99/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 139255904.0000 - mean_absolute_error: 8614.3994 - val_loss: 304357472.0000 - val_mean_absolute_error: 14161.0977\n",
      "Epoch 100/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 138535328.0000 - mean_absolute_error: 8587.9316 - val_loss: 303162624.0000 - val_mean_absolute_error: 14131.6152\n",
      "Epoch 101/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 138363008.0000 - mean_absolute_error: 8584.6504 - val_loss: 305837888.0000 - val_mean_absolute_error: 14206.6963\n",
      "Epoch 102/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 139424160.0000 - mean_absolute_error: 8627.8545 - val_loss: 304701504.0000 - val_mean_absolute_error: 14176.9365\n",
      "Epoch 103/200\n",
      "1573/1573 [==============================] - 5s 3ms/step - loss: 138716640.0000 - mean_absolute_error: 8595.6807 - val_loss: 303467456.0000 - val_mean_absolute_error: 14133.4609\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = compile_and_fit(lstm_model, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99327d-3c30-483f-9376-339643d7860d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce some qualitative results\n",
    "w2.plot(lstm_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
